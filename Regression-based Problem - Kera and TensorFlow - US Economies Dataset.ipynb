{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression-based neural networks - Using Kera and TensorFlow - Car Dataset\n",
    "Keras is an application programming interface (API) used for running high-level neural networks. The model runs on top of TensorFlow which was developed by Google. Keras is recognized as one of the most popular deep learning libraries in Python for research and development because of it ease of use and its simplicity. However, the Scikit-learn library is the most popular library for general machine learning in Python. Most times, building a very complex deep learning network could be challenging but with Keras, this can be achieved with only a few lines of code.\n",
    "\n",
    "I will be using Keras Library  to build a regression models using the US Economic time series Data set, The dataset could be download here and saved into CSV - https://raw.githubusercontent.com/tidyverse/ggplot2/master/data-raw/economics.csv or https://github.com/tidyverse/ggplot2/blob/master/data-raw/economics.csv. \n",
    "\n",
    "The data set contains 574 rows and 5 variables. \n",
    "\n",
    "- Date - The date the data was recorded\n",
    "- Psavert - Personal savings rate.\n",
    "- Pce     - Personal consumption expenditures, in billions of dollars.\n",
    "- Uempmed - Median duration of unemployment, in weeks.\n",
    "- Pop     - Total population, in thousands.\n",
    "- Unemploy- Number of unemployed in thousands (dependent variable). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Neural Network\n",
    "The basic architecture of the deep learning neural network, which we will be following, consists of three main components.\n",
    "\n",
    "1) Input Layer: This is where the training observations are fed. The number of predictor variables is also specified here through the neurons.\n",
    "\n",
    "2) Hidden Layers: These are the intermediate layers between the input and output layers. The deep neural network learns about the relationships involved in data in this component.\n",
    "\n",
    "3) Output Layer: This is the layer where the final output is extracted from whatâ€™s happening in the previous two layers. In case of regression problems, the output later will have one neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Across the Nations of the world, unemployment has become a major socio-economic and political problem. However, each government has a specific way of managing this very task, while managing unemployment within an economy, it is very important to predict it as well. I will be building a deep learning regression model using Keras to predict unemployment.\n",
    "\n",
    "# Model Evaluation Metric\n",
    "\n",
    "The performance of the model using Root Mean Squared Error (RMSE) which is commonly used metric when evaluating problems. RMSE measures the average magnitude of the residuals or error. Mathematically, it is computed as the square root of the average of square differences between predicted and actual values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - To Load the Required Python Libraries and Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Keras specific\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - To read the Data and Conduct Basic Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first line of code reads in the data as pandas dataframe\n",
    "\n",
    "data = pd.read_csv('economics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pce</th>\n",
       "      <th>pop</th>\n",
       "      <th>psavert</th>\n",
       "      <th>uempmed</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/07/1967</td>\n",
       "      <td>506.7</td>\n",
       "      <td>198712.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/08/1967</td>\n",
       "      <td>509.8</td>\n",
       "      <td>198911.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/09/1967</td>\n",
       "      <td>515.6</td>\n",
       "      <td>199113.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/10/1967</td>\n",
       "      <td>512.2</td>\n",
       "      <td>199311.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/11/1967</td>\n",
       "      <td>517.4</td>\n",
       "      <td>199498.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    pce       pop  psavert  uempmed  unemploy\n",
       "0  01/07/1967  506.7  198712.0     12.6      4.5      2944\n",
       "1  01/08/1967  509.8  198911.0     12.6      4.7      2945\n",
       "2  01/09/1967  515.6  199113.0     11.9      4.6      2958\n",
       "3  01/10/1967  512.2  199311.0     12.9      4.9      3143\n",
       "4  01/11/1967  517.4  199498.0     12.8      4.7      3066"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view or prints the shape \n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 574 rows/observations and 6 columns/variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pce</th>\n",
       "      <th>pop</th>\n",
       "      <th>psavert</th>\n",
       "      <th>uempmed</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4820.092683</td>\n",
       "      <td>257159.652662</td>\n",
       "      <td>8.567247</td>\n",
       "      <td>8.608711</td>\n",
       "      <td>7771.310105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3556.803613</td>\n",
       "      <td>36682.398508</td>\n",
       "      <td>2.964179</td>\n",
       "      <td>4.106645</td>\n",
       "      <td>2641.959180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>506.700000</td>\n",
       "      <td>198712.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1578.300000</td>\n",
       "      <td>224896.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3936.850000</td>\n",
       "      <td>253060.000000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7626.325000</td>\n",
       "      <td>290290.750000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>8685.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12193.800000</td>\n",
       "      <td>320402.295000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>15352.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pce            pop     psavert     uempmed      unemploy\n",
       "count    574.000000     574.000000  574.000000  574.000000    574.000000\n",
       "mean    4820.092683  257159.652662    8.567247    8.608711   7771.310105\n",
       "std     3556.803613   36682.398508    2.964179    4.106645   2641.959180\n",
       "min      506.700000  198712.000000    2.200000    4.000000   2685.000000\n",
       "25%     1578.300000  224896.000000    6.400000    6.000000   6284.000000\n",
       "50%     3936.850000  253060.000000    8.400000    7.500000   7494.000000\n",
       "75%     7626.325000  290290.750000   11.100000    9.100000   8685.500000\n",
       "max    12193.800000  320402.295000   17.300000   25.200000  15352.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this shows the summary statistics of the numerical variables\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the statistical summary, it shows that the variables/rows has 574 as 'count' which is the same thing with the number of records in the dataset. In this scenario, there is no missing values. \n",
    "\n",
    "However, in more real life data set, i.e. when working with large data set, there is will more missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 574 entries, 0 to 573\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   date      574 non-null    object \n",
      " 1   pce       574 non-null    float64\n",
      " 2   pop       574 non-null    float64\n",
      " 3   psavert   574 non-null    float64\n",
      " 4   uempmed   574 non-null    float64\n",
      " 5   unemploy  574 non-null    int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 27.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date column has no contribution to the prediction of the model, we need to drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pce</th>\n",
       "      <th>pop</th>\n",
       "      <th>psavert</th>\n",
       "      <th>uempmed</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>506.7</td>\n",
       "      <td>198712.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>509.8</td>\n",
       "      <td>198911.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>515.6</td>\n",
       "      <td>199113.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512.2</td>\n",
       "      <td>199311.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>517.4</td>\n",
       "      <td>199498.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pce       pop  psavert  uempmed  unemploy\n",
       "0  506.7  198712.0     12.6      4.5      2944\n",
       "1  509.8  198911.0     12.6      4.7      2945\n",
       "2  515.6  199113.0     11.9      4.6      2958\n",
       "3  512.2  199311.0     12.9      4.9      3143\n",
       "4  517.4  199498.0     12.8      4.7      3066"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - To Create an Arrays for the Features and the Response Variable\n",
    "\n",
    "Here, we identify the target variable/column and also we define the feature columns, that is, the reset of the columns to be used for prediction purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pce', 'pop', 'psavert', 'uempmed', 'unemploy'], dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To list all the variables/columns in the dataset\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create an object of the target variable\n",
    "\n",
    "target_column = ['unemploy'] \n",
    "\n",
    "# To list all the features, excluding the target variable 'unemploy'\n",
    "predictors = list(set(list(data.columns))-set(target_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization of the Predictors Columns\n",
    "Next, we need to normalizes the predictors. Since the units of the variables differ very significantly and which could influence the modeling process, it is very important to normalizes the columns to be used for prediction. In this situation when there is variation in unit of the data as seen when we use 'describe()' function above, we will do what is called \"Normalization\" using scaling of the predictors between 0 and 1 as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[predictors] = data[predictors]/data[predictors].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to display the summary of the normalized data set. All the independent variables 'y' are now been scaled between 0 and 1. However, the target variable remains unchanged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pce</th>\n",
       "      <th>pop</th>\n",
       "      <th>psavert</th>\n",
       "      <th>uempmed</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.395290</td>\n",
       "      <td>0.802615</td>\n",
       "      <td>0.495217</td>\n",
       "      <td>0.341616</td>\n",
       "      <td>7771.310105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.291690</td>\n",
       "      <td>0.114489</td>\n",
       "      <td>0.171340</td>\n",
       "      <td>0.162962</td>\n",
       "      <td>2641.959180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.620195</td>\n",
       "      <td>0.127168</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>2685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.129435</td>\n",
       "      <td>0.701918</td>\n",
       "      <td>0.369942</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>6284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.322857</td>\n",
       "      <td>0.789820</td>\n",
       "      <td>0.485549</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>7494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.625426</td>\n",
       "      <td>0.906020</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>8685.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15352.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pce         pop     psavert     uempmed      unemploy\n",
       "count  574.000000  574.000000  574.000000  574.000000    574.000000\n",
       "mean     0.395290    0.802615    0.495217    0.341616   7771.310105\n",
       "std      0.291690    0.114489    0.171340    0.162962   2641.959180\n",
       "min      0.041554    0.620195    0.127168    0.158730   2685.000000\n",
       "25%      0.129435    0.701918    0.369942    0.238095   6284.000000\n",
       "50%      0.322857    0.789820    0.485549    0.297619   7494.000000\n",
       "75%      0.625426    0.906020    0.641618    0.361111   8685.500000\n",
       "max      1.000000    1.000000    1.000000    1.000000  15352.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Creating the Training and Test Datasets\n",
    "\n",
    "The data have to be splitted into both training and testing data (i.e. 70% traning data and 30% testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 4)\n",
      "(173, 4)\n"
     ]
    }
   ],
   "source": [
    "# To create arrays of independent (X) and dependent (y) variables, respectively.\n",
    "\n",
    "X = data[predictors].values\n",
    "y = data[target_column].values\n",
    "\n",
    "\n",
    "# To split the data set into training and test dataset ( divided into 70% training and 30% testing data set)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "\n",
    "\n",
    "# To print the shape of the both training data set and Test data set\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the shape of the training set is (401 observations of 4 variables) while the shape of the test set (173 observations of 4 variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Building the Deep Learning Regression Model\n",
    "\n",
    "To build the Regression Model, the deep learning in keras will be used. The activation function used for the hidden layer in neural network is called \"Rectified Linear Unit\" or ReLU. ReLU is the most widely used activation function because of its non-linear advantages and also it ability to not activate all the neurons at the same time. This implies that at a time, only a few neurons are activated, and this make the network to sparse and very efficient. We will firsst define the model and also we will be using the sequential model because the network consists of a linear stack of layers as shown below:\n",
    "\n",
    " Then we repeat the same process in the third and fourth line of codes for the hidden layers, this time without the input_dim parameter. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to define the model\n",
    "\n",
    "# Calls for sequential constructor\n",
    "model = Sequential()\n",
    "\n",
    "# To specify the activation function for first layer and the number of input dimensions which is 4 predictors in this case\n",
    "model.add(Dense(500, input_dim=4, activation= \"relu\"))\n",
    "\n",
    "# To repeat the process for the hidden layers without the input dimension (input_dim) parameter\n",
    "model.add(Dense(100, activation= \"relu\"))\n",
    "model.add(Dense(50, activation= \"relu\"))\n",
    "\n",
    "# To create the output layer with one node that is expected to output the number of unemployed in thousands\n",
    "model.add(Dense(1))\n",
    "\n",
    "#model.summary() #Print model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Define an Optimizer and the Loss Measure for Training\n",
    "\n",
    "I will define the optimizer and the loss measure for training. The Mean Square Error will be used and serves as the loss measure and the \"adam\" optimizer is the minimization algorithm. The actual benefit of the \"adam\" optimizer is that we don't need to specify the learning rate as in the case of gradient descent. That means, it will save the task of optimizing the learning rate for the model. This can be achieved as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 68122288.0000 - mean_squared_error: 68122288.0000\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 68079808.0000 - mean_squared_error: 68079808.0000\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 67958816.0000 - mean_squared_error: 67958816.0000\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 67662256.0000 - mean_squared_error: 67662256.0000\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 67022444.0000 - mean_squared_error: 67022444.0000\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 65751828.0000 - mean_squared_error: 65751828.0000\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 63460376.0000 - mean_squared_error: 63460376.0000\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 59785196.0000 - mean_squared_error: 59785196.0000\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 54263304.0000 - mean_squared_error: 54263304.0000\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 46507200.0000 - mean_squared_error: 46507200.0000\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 36699364.0000 - mean_squared_error: 36699364.0000\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 26017942.0000 - mean_squared_error: 26017942.0000\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 15483584.0000 - mean_squared_error: 15483584.0000\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7964894.0000 - mean_squared_error: 7964895.0000\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4401247.0000 - mean_squared_error: 4401247.0000\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3640836.2500 - mean_squared_error: 3640836.2500\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3613472.0000 - mean_squared_error: 3613472.0000\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3569555.7500 - mean_squared_error: 3569555.7500\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3530279.5000 - mean_squared_error: 3530279.5000\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3499586.5000 - mean_squared_error: 3499586.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a16dcef108>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the Mean Square Error to serve as loss measure and using 'adam' optimizer as the minimization algorithm\n",
    "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "# To fits the model on the training dataset, using 'epochs' which respresent the number of training iterations, epochs equal 20\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - To Make Prediction on the Test Data and Compute Evaluation Metrics\n",
    "\n",
    "I will make prediction on both the train and test data. The evaluation metrics to be used is \"Root Mean Square Error (RMSE)\" and the RMSE values for both train and test data will be printed respectively as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1866.394427714595\n",
      "1825.6014425717678\n"
     ]
    }
   ],
   "source": [
    "# To Predict on the train data\n",
    "pred_train= model.predict(X_train)\n",
    "\n",
    "# To print the RMSE value on the train data\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train)))\n",
    "\n",
    "# To Predict on the test data\n",
    "pred= model.predict(X_test)\n",
    "\n",
    "# To print the RMSE value on the test data\n",
    "print(np.sqrt(mean_squared_error(y_test,pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Evaluation of the Model Performance\n",
    "\n",
    "Based on the output from RMSE values above, the RMSE is the evaluation metric, and the lower the RMSE value, the better the model performance. Therefore, the RMSE values for train data was 1856 thousand and 1825 thousand for test data. However, in contrast to accuracy, it is not straightforward to interpret RMSE as we would have to look at the unit which in our case is in thousands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Conclusion\n",
    "\n",
    "I have built Regression Models using the Deep Learning Framework known as \"Keras\" using the US Economics Time Series dataset and the deep learning regression model to predict the number of unemployed population in thousands. The model acheive a better and stable performance with little variance in the train and test set RMSE. The units of the target variable is in thousands and this also have effect on the RMSE value.\n",
    "\n",
    "The performance of the model can also be further enhanced by other iterations such as changing the number of neurons, add more to the hidden layers and increase the number of the 'epochs' and this can be tried out to see the impact on the model performance.\n",
    "\n",
    "Aside, using Deep Learning Keras library, some other algorithm can be used to model using same dataset such as Random Forest, Decision Tree, Gradient Boosting, Support Vector Machines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
